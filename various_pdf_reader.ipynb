{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "## 참고 : https://excelsior-cjh.tistory.com/62?category=928322\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw = parser.from_file('sample.pdf')\n",
    "# print(raw['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = raw['content']\n",
    "# sentences = sent_tokenize(text)\n",
    "sentences = text.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[:1][0].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdfminer.pdfpage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fb5b2a8c96a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpdfminer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLAParams\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpdfminer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdfinterp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPDFResourceManager\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPDFPageInterpreter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpdfminer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdfpage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPDFPage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pdfminer.pdfpage'"
     ]
    }
   ],
   "source": [
    "# This works in python 3\n",
    "# required python packages\n",
    "# tabula-py==1.0.0\n",
    "# PyPDF2==1.26.0\n",
    "# Pillow==4.0.0\n",
    "# pdfminer.six==20170720\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "from io import StringIO\n",
    "\n",
    "import requests\n",
    "import tabula\n",
    "from PIL import Image\n",
    "from PyPDF2 import PdfFileWriter, PdfFileReader\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tabula\n",
    "!pip install PyPDF2\n",
    "!pip install pdfminer3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdfminer3k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    local_filename = local_filename.replace(\"%20\", \"_\")\n",
    "    r = requests.get(url, stream=True)\n",
    "    print(r)\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "    return local_filename\n",
    "\n",
    "\n",
    "class PDFExtractor():\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "\n",
    "    # Downloading File in local\n",
    "    def break_pdf(self, filename, start_page=-1, end_page=-1):\n",
    "        pdf_reader = PdfFileReader(open(filename, \"rb\"))\n",
    "        # Reading each pdf one by one\n",
    "        total_pages = pdf_reader.numPages\n",
    "        if start_page == -1:\n",
    "            start_page = 0\n",
    "        elif start_page < 1 or start_page > total_pages:\n",
    "            return \"Start Page Selection Is Wrong\"\n",
    "        else:\n",
    "            start_page = start_page - 1\n",
    "\n",
    "        if end_page == -1:\n",
    "            end_page = total_pages\n",
    "        elif end_page < 1 or end_page > total_pages - 1:\n",
    "            return \"End Page Selection Is Wrong\"\n",
    "        else:\n",
    "            end_page = end_page\n",
    "\n",
    "        for i in range(start_page, end_page):\n",
    "            output = PdfFileWriter()\n",
    "            output.addPage(pdf_reader.getPage(i))\n",
    "            with open(str(i + 1) + \"_\" + filename, \"wb\") as outputStream:\n",
    "                output.write(outputStream)\n",
    "\n",
    "    def extract_text_algo_1(self, file):\n",
    "        pdf_reader = PdfFileReader(open(file, 'rb'))\n",
    "        # creating a page object\n",
    "        pageObj = pdf_reader.getPage(0)\n",
    "\n",
    "        # extracting extract_text from page\n",
    "        text = pageObj.extractText()\n",
    "        text = text.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "        return text\n",
    "\n",
    "    def extract_text_algo_2(self, file):\n",
    "        pdfResourceManager = PDFResourceManager()\n",
    "        retstr = StringIO()\n",
    "        la_params = LAParams()\n",
    "        device = TextConverter(pdfResourceManager, retstr, codec='utf-8', laparams=la_params)\n",
    "        fp = open(file, 'rb')\n",
    "        interpreter = PDFPageInterpreter(pdfResourceManager, device)\n",
    "        password = \"\"\n",
    "        max_pages = 0\n",
    "        caching = True\n",
    "        page_num = set()\n",
    "\n",
    "        for page in PDFPage.get_pages(fp, page_num, maxpages=max_pages, password=password, caching=caching,\n",
    "                                      check_extractable=True):\n",
    "            interpreter.process_page(page)\n",
    "\n",
    "        text = retstr.getvalue()\n",
    "        text = text.replace(\"\\t\", \"\").replace(\"\\n\", \"\")\n",
    "\n",
    "        fp.close()\n",
    "        device.close()\n",
    "        retstr.close()\n",
    "        return text\n",
    "\n",
    "    def extract_text(self, file):\n",
    "        text1 = self.extract_text_algo_1(file)\n",
    "        text2 = self.extract_text_algo_2(file)\n",
    "\n",
    "        if len(text2) > len(str(text1)):\n",
    "            return text2\n",
    "        else:\n",
    "            return text1\n",
    "\n",
    "    def extarct_table(self, file):\n",
    "\n",
    "        # Read pdf into DataFrame\n",
    "        try:\n",
    "            df = tabula.read_pdf(file, output_format=\"csv\")\n",
    "        except:\n",
    "            print(\"Error Reading Table\")\n",
    "            return\n",
    "\n",
    "        print(\"\\nPrinting Table Content: \\n\", df)\n",
    "        print(\"\\nDone Printing Table Content\\n\")\n",
    "\n",
    "    def tiff_header_for_CCITT(self, width, height, img_size, CCITT_group=4):\n",
    "        tiff_header_struct = '<' + '2s' + 'h' + 'l' + 'h' + 'hhll' * 8 + 'h'\n",
    "        return struct.pack(tiff_header_struct,\n",
    "                           b'II',  # Byte order indication: Little indian\n",
    "                           42,  # Version number (always 42)\n",
    "                           8,  # Offset to first IFD\n",
    "                           8,  # Number of tags in IFD\n",
    "                           256, 4, 1, width,  # ImageWidth, LONG, 1, width\n",
    "                           257, 4, 1, height,  # ImageLength, LONG, 1, lenght\n",
    "                           258, 3, 1, 1,  # BitsPerSample, SHORT, 1, 1\n",
    "                           259, 3, 1, CCITT_group,  # Compression, SHORT, 1, 4 = CCITT Group 4 fax encoding\n",
    "                           262, 3, 1, 0,  # Threshholding, SHORT, 1, 0 = WhiteIsZero\n",
    "                           273, 4, 1, struct.calcsize(tiff_header_struct),  # StripOffsets, LONG, 1, len of header\n",
    "                           278, 4, 1, height,  # RowsPerStrip, LONG, 1, lenght\n",
    "                           279, 4, 1, img_size,  # StripByteCounts, LONG, 1, size of extract_image\n",
    "                           0  # last IFD\n",
    "                           )\n",
    "\n",
    "    def extract_image(self, filename):\n",
    "        number = 1\n",
    "        pdf_reader = PdfFileReader(open(filename, 'rb'))\n",
    "\n",
    "        for i in range(0, pdf_reader.numPages):\n",
    "\n",
    "            page = pdf_reader.getPage(i)\n",
    "\n",
    "            try:\n",
    "                xObject = page['/Resources']['/XObject'].getObject()\n",
    "            except:\n",
    "                print(\"No XObject Found\")\n",
    "                return\n",
    "\n",
    "            for obj in xObject:\n",
    "\n",
    "                try:\n",
    "\n",
    "                    if xObject[obj]['/Subtype'] == '/Image':\n",
    "                        size = (xObject[obj]['/Width'], xObject[obj]['/Height'])\n",
    "                        data = xObject[obj]._data\n",
    "                        if xObject[obj]['/ColorSpace'] == '/DeviceRGB':\n",
    "                            mode = \"RGB\"\n",
    "                        else:\n",
    "                            mode = \"P\"\n",
    "\n",
    "                        image_name = filename.split(\".\")[0] + str(number)\n",
    "\n",
    "                        print(xObject[obj]['/Filter'])\n",
    "\n",
    "                        if xObject[obj]['/Filter'] == '/FlateDecode':\n",
    "                            data = xObject[obj].getData()\n",
    "                            img = Image.frombytes(mode, size, data)\n",
    "                            img.save(image_name + \"_Flate.png\")\n",
    "                            # save_to_s3(imagename + \"_Flate.png\")\n",
    "                            print(\"Image_Saved\")\n",
    "\n",
    "                            number += 1\n",
    "                        elif xObject[obj]['/Filter'] == '/DCTDecode':\n",
    "                            img = open(image_name + \"_DCT.jpg\", \"wb\")\n",
    "                            img.write(data)\n",
    "                            # save_to_s3(imagename + \"_DCT.jpg\")\n",
    "                            img.close()\n",
    "                            number += 1\n",
    "                        elif xObject[obj]['/Filter'] == '/JPXDecode':\n",
    "                            img = open(image_name + \"_JPX.jp2\", \"wb\")\n",
    "                            img.write(data)\n",
    "                            # save_to_s3(imagename + \"_JPX.jp2\")\n",
    "                            img.close()\n",
    "                            number += 1\n",
    "                        elif xObject[obj]['/Filter'] == '/CCITTFaxDecode':\n",
    "                            if xObject[obj]['/DecodeParms']['/K'] == -1:\n",
    "                                CCITT_group = 4\n",
    "                            else:\n",
    "                                CCITT_group = 3\n",
    "                            width = xObject[obj]['/Width']\n",
    "                            height = xObject[obj]['/Height']\n",
    "                            data = xObject[obj]._data  # sorry, getData() does not work for CCITTFaxDecode\n",
    "                            img_size = len(data)\n",
    "                            tiff_header = self.tiff_header_for_CCITT(width, height, img_size, CCITT_group)\n",
    "                            img_name = image_name + '_CCITT.tiff'\n",
    "                            with open(img_name, 'wb') as img_file:\n",
    "                                img_file.write(tiff_header + data)\n",
    "\n",
    "                            # save_to_s3(img_name)\n",
    "                            number += 1\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        return number\n",
    "\n",
    "    def read_pages(self, start_page=-1, end_page=-1):\n",
    "\n",
    "        # Downloading file locally\n",
    "        downloaded_file = download_file(self.url)\n",
    "        print(downloaded_file)\n",
    "\n",
    "        # breaking PDF into number of pages in diff pdf files\n",
    "        self.break_pdf(downloaded_file, start_page, end_page)\n",
    "\n",
    "        # creating a pdf reader object\n",
    "        pdf_reader = PdfFileReader(open(downloaded_file, 'rb'))\n",
    "\n",
    "        # Reading each pdf one by one\n",
    "        total_pages = pdf_reader.numPages\n",
    "\n",
    "        if start_page == -1:\n",
    "            start_page = 0\n",
    "        elif start_page < 1 or start_page > total_pages:\n",
    "            return \"Start Page Selection Is Wrong\"\n",
    "        else:\n",
    "            start_page = start_page - 1\n",
    "\n",
    "        if end_page == -1:\n",
    "            end_page = total_pages\n",
    "        elif end_page < 1 or end_page > total_pages - 1:\n",
    "            return \"End Page Selection Is Wrong\"\n",
    "        else:\n",
    "            end_page = end_page\n",
    "\n",
    "        for i in range(start_page, end_page):\n",
    "            # creating a page based filename\n",
    "            file = str(i + 1) + \"_\" + downloaded_file\n",
    "\n",
    "            print(\"\\nStarting to Read Page: \", i + 1, \"\\n -----------===-------------\")\n",
    "\n",
    "            file_text = self.extract_text(file)\n",
    "            print(file_text)\n",
    "            self.extract_image(file)\n",
    "\n",
    "            self.extarct_table(file)\n",
    "            os.remove(file)\n",
    "            print(\"Stopped Reading Page: \", i + 1, \"\\n -----------===-------------\")\n",
    "\n",
    "        os.remove(downloaded_file)\n",
    "\n",
    "\n",
    "# I have tested on these 3 pdf files\n",
    "# url = \"http://s3.amazonaws.com/NLP_Project/Original_Documents/Healthcare-January-2017.pdf\"\n",
    "url = \"http://s3.amazonaws.com/NLP_Project/Original_Documents/Sample_Test.pdf\"\n",
    "# url = \"http://s3.amazonaws.com/NLP_Project/Original_Documents/Sazerac_FS_2017_06_30%20Annual.pdf\"\n",
    "# creating the instance of class\n",
    "pdf_extractor = PDFExtractor(url)\n",
    "\n",
    "# Getting desired data out\n",
    "pdf_extractor.read_pages(15, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
